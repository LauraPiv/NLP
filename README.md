# NLP - Neural Language Processing: Summarization Algorithm
This repository presents a summarization algorithm based on Neural Language Processing (NLP) techniques to efficiently summarize large volumes of text. The algorithm uses neural networks to generate coherent and informative summaries of textual documents, preserving the essence and most important information from the original content.

## Table of Contents
- [1. Overview](Overview)
- [2. Dependencies](Version)
- [3. Technologies Used](Technologies)
- [4. Copyright](copyright)


## 1. Overview
The summarization algorithm presented here applies Neural Networks techniques for both abstractive and extractive summarization of texts. It can be trained on specific corpora and is capable of creating concise summaries from documents in various domains, such as scientific articles, news, or even blog posts.

There are two main types of summarization the algorithm can perform:

  - Extractive Summarization: Selects and extracts the most important parts of the original text.
  - Abstractive Summarization: Generates a new summary in different words or phrases from the original text, similar to how humans summarize content.
This project utilizes a neural network model based on architectures like Transformer and BERT to improve the quality and fluency of the generated summaries.

## 2. Dependencies
Python 3.x
pip (Python package manager)

## 3. Technologies Used
Python: Main programming language for development.
PyTorch: Deep learning framework used to implement and train the neural model.
Hugging Face Transformers: Library providing pre-trained NLP models to facilitate the implementation of advanced language processing techniques.
NLTK / spaCy: Auxiliary libraries for text preprocessing and linguistic analysis.

## 4. Copyright
- Direitos Autorais

Este projeto e seu código são [@LauraPiv], [2024]. Todos os direitos reservados.

